{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Embedded ML - Lab 2.2: TensorFlow Lite"
      ],
      "metadata": {
        "id": "7SFBFiQlYlva"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this lab you will learn the basics of TensorFlow Lite, a complement of TensorFlow that allows you to optimize and run models on constrained devices. It provides a much lighter runtime than TensorFlow but it only supports a subset of the tools available in full TensorFlow.\n",
        "\n",
        "In this lab you might be given some helper functions but you are expected to write most of the code and be able to explain it at a high level of abstraction and also to modify any part of it."
      ],
      "metadata": {
        "id": "svldvvGfmN8q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Learning outcomes\n",
        "\n",
        "\n",
        "* Explain the basic concepts associated with TensorFlow Lite\n",
        "* Develop applications following the basic TensorFlow Lite workflow\n",
        "* Implement post-training quantization using TensorFlow Lite tools"
      ],
      "metadata": {
        "id": "lQK0RRRuY3rJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TensorFlow Lite workflow\n",
        "After having built a TensorFlow model, you can convert it to the TensorFlow Lite representation. Then you can run it with the TensorFlow Lite interpreter on your development environment before exporting it and copying it to the target device.\n",
        "\n",
        "To run the model with TensorFlow Lite you should load the model to the TensorFlow Lite interpreter, allocate the input/output tensors, pass the input data and finally run inference. Notice that TensorFlow Lite API calls are different from those of TensorFlow.\n",
        "\n",
        "In this part of the assignment, you should create and train a simple model (e.g. a one-neuron network) with TensorFlow and then save it. Then follow the TensorFlow Lite workflow until you are able to run inference and validate the outputs."
      ],
      "metadata": {
        "id": "l8wat6Kxul5R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### TENSORFLOW BASIC WORKFLOW\n",
        "\n",
        "# Create the model\n",
        "\n",
        "# Compile the model\n",
        "\n",
        "# Train the model\n",
        "\n",
        "# Save the model to a file"
      ],
      "metadata": {
        "id": "fs6U9xbNuz3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### TENSORFLOR LITE BASIC WORKFLOW\n",
        "\n",
        "# Load and convert exported model from file\n",
        "\n",
        "# Set up input/output tensors\n",
        "\n",
        "# Set input values\n",
        "\n",
        "# Run inference\n",
        "\n",
        "# Get outputs"
      ],
      "metadata": {
        "id": "OcQ6-6l8sHgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vision model with TensorFlow Lite\n",
        "\n",
        "In this part of the assignment, you should import a fine-tuned model that is meant for constrained or mobile devices. Then you should follow the TensorFlow Lite workflow until you are able to run inference and obtain acceptable results."
      ],
      "metadata": {
        "id": "xpPgM38-6tFQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Post-training quantization\n",
        "Finally, in this part of the assignment you should compare the size and accuracy of the TensorFlow Lite model by using various configurations and against the uncompressed baseline."
      ],
      "metadata": {
        "id": "T25pOIS7kcym"
      }
    }
  ]
}